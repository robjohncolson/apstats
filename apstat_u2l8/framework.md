Topic 2.8: Least Squares Regression
SKILLS
Data Analysis (2.C): Calculate summary statistics, relative positions of points within a distribution, correlation, and predicted response.
Statistical Argumentation (4.B): Interpret statistical calculations and findings to assign meaning or assess a claim.
ENDURING UNDERSTANDING
DAT-1: Regression models may allow us to predict responses to changes in an explanatory variable.
LEARNING OBJECTIVES & ESSENTIAL KNOWLEDGE
LEARNING OBJECTIVE
DAT-1.G: Estimate parameters for the least-squares regression line model. [Skill 2.C]
ESSENTIAL KNOWLEDGE
DAT-1.G.1: The least-squares regression model minimizes the sum of the squares of the residuals and contains the point (x̄, ȳ).
DAT-1.G.2: The slope, b, of the regression line can be calculated as b = r(s_y / s_x), where r is the correlation between x and y, s_y is the sample standard deviation of the response variable, y, and s_x is the sample standard deviation of the explanatory variable, x.
DAT-1.G.3: Sometimes, the y-intercept of the line does not have a logical interpretation in context.
DAT-1.G.4: In simple linear regression, r² is the square of the correlation, r. It is also called the coefficient of determination. r² is the proportion of variation in the response variable that is explained by the explanatory variable in the model.
LEARNING OBJECTIVE
DAT-1.H: Interpret coefficients for the least-squares regression line model. [Skill 4.B]
ESSENTIAL KNOWLEDGE
DAT-1.H.1: The coefficients of the least-squares regression model are the estimated slope and y-intercept.
DAT-1.H.2: The slope is the amount that the predicted y-value changes for every unit increase in x.
DAT-1.H.3: The y-intercept value is the predicted value of the response variable when the explanatory variable is equal to 0. The formula for the y-intercept, a, is a = ȳ - bx̄.